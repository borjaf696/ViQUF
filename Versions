Version actual:
    - Complete 3:
            - Para A-B
            - getInNeighs(B) != A - obtener PE de todos los padres de B - extra_neigh
            - getOutNeighs(A) != B - obtener PE de todos los hijos de A - extra_node
            - PE(A) - extra_neigh
            - PE(B) - extra_node
      Update:
            - Para eliminar la información compartida extra entre diversos vecinos se plantea lo siguiente:
                    - (A-D)+(A y C)
                    - (B-c)+)B y D)
      - Post-procesados de pair-end - eliminamos aquellos que estén fuera de control (LCL,UCL)
             - Para meta = 2; para quasi = 3 - Hay que usar la longitud del unitig - mirar las modas
             - Incluso con la length sigue siendo mala aproximación - LCL negativo!!
             - Done!
             - Se ha eliminado el post-procesado por pair-node (a nivel individual)
      - Corregir los cliques - guiarlos en base a la frecuencia del unitig?
      - Todos los cliques deben tener información tanto del padre como del hijo
      - Nueva heurística:
            - clique intersecado con el padre - i1 - si i1 subset hijo - eliminar
            - clique intersecado con el hijo - i2 - si i2 subset padre - eliminar
            - ¿Es el hijo subconjunto del padre o viceversa?
            - Si esto pasa - evaluar ese clique contra el resto - si existe otro clique de la que este sea un subconjunto -> eliminar
      - Probar - resolver el problema asignando flujo a las ¿aristas? y luego resolver el problema con el camino más pesado.
        - Creamos 3 sources y 3 targets: 1 para englobar todos los s/t, otro como sumideros cuando no cuadren los números y otros como global s/s.
        - Cost function 1 /sqrt(cov(u,v))
        - Try dividiendo los nodos y metiendo capacidad máxima a la arista entre ellos
        - Mirar funciones de coste + tratar de ver como hacer con las fuentes:
            * Caso fuentes y target - la idea es ver si con una distribución uniforme del flujo entre las aristas cabría la posibilidad de que una arista fuese missing:
                * In_flow / aritas.size() < diff(abundance, in_flow) -> source_potencial
                * Out_flow / aristas.size() < diff(abundance, out_flow) -> target_potencial
        - Coste - opción: (cov(u,v) - cov_padres) / sqrt(cov(u,v)) - la idea es priorizar las cercanas y de mayor capacidad.
            * Corregir funciones de coste!!!! Usar el split en múltiples aristas paralelas para poder simular las funciones de coste no lineal.
            * Mirar de buscar una función para llenar primero las más cercanas al flujo. Solved
            * Revisar flujos - por que hay algo que no cuadra.
        - Fijado un flujo de 30 mínimo para poder obtener un camino.
        - Dados todos los nodos potenciales - eliminar aquellos cuya PE sea subconjunto de otra (no hacer la unión que puede no tener sentido)
        **** Polishing **** CUIDADO ESTO ESTÁ SIENDO TESTEADO
            - Saltar nodos con frecuencia < del I_quantile al 5%
            - Saltar nodos con frecuencia < del LCL (al 5% para sintéticos pendiente en datos reales)
            - Saltar emparejamientos < del LCL y > UCL
            - Pensar en como calcular el LCL (para datos reales)
            *** Paired-end reads ***
                - Polishing las paired-end evitando enlaces con frecuencia = 1.
                    * Buscaremos pues enlaces que vengan dados por más de una lectura.
                    * Bitvector de 2^30 bits que mira bit_vector[(unitigs_left << 15 | unitig_right)] = 1:
                        * Si vale 0 -> se pone a 1
                        * Si vale 1 -> se añade el par (en una misma lectura si se ha puesto a 1 no se pone más veces)
                        * REVISAR ESTO
                    * Bloom filter? - Opción de implementación contar hasta n usando un bloom filter. Reservamos 1 Gb con 2^30 posiciones misma metodología.
                    Pasamos solo aquellos que superen cierto valor umbral.

        **** Grafo de redes de flujo ****
        - Corrección por ciclos - restar el número mínimo de alcances para poner valor 0 en reached_by
            + Corregido:
                * Seleccionamos la arista de mayor flujo como norma
                * Se seleccionan los caminos con número mínimo de veces alcanzado
            + Corrección del grafo:
                * Si el "flujo" entrante y saliente de un nodo es 1.X veces más pequeño o más grande que el flujo que transita el nodo
                entonces el flujo del nodo se ve modificado al máximo de [in_flow, out_flow]
        - Detección de enlaces erróneos - untigs que son alcanzados pero no deberían:
            + Obtener por cuantos es alcanzado y a cuantos alcanza cada nodo.
            + Sumarlos y verificar que existe un patrón.
        - Flow to paths:
            + Alcanzar el flujo - es decir convertir el flujo íntegramente en caminos
            + Haber recorrido todos los nodos (path cover)
            + Obtener el flujo esperado entre A-B (como la frecuencia de la arista) y no añadir los caminos una vez alcanzado el flujo esperado (el flujo esperado
            según nuestra nueva aproximación es el flujo (sin ajustar) de las aristas)
            + Chequear los "paths": Si paths entre A -> B, path_1 (n1,n2) y path_2 (n3,n4) donde subset(n1,n3) y in_parent(B) > 1 entonces remove(path_2(n1,n3))...
            !Chequear!
        - Offset network flow to solution flow:
            + Available_flow[(x,y)] + Offset_flow(y,x) - Offset_flow(x,y)
        - Cambiar a la versión de aristas con capacidad 1 tantas como flujo (máximo flujo en las aristas) e incorporar
            + coste = (f(i) - f(i-1))^exponent
            + coste(1) = f(1*roundingBase / freq)^2, en nuestro caso roundingBase es 100 /no lo veo
        - Opción B:
            + Usar flujo reajustado - usar la frecuencia entre (A,B) reajustar el flujo como:
                * max_freq - abs(freq(A,B) - freq(p_a,p_b)) (manejado por READJUST) - TODO: Mirar si se están cogiendo bien los valores (en el orden adecuado)
                * Nueva corrección - normalización del flujo en la red: New_max*(abs(val-max))/max+New_min
        *** Preprocesado ***
        - Se ha incluido la versión del knee (Elbow) para el cálculo conservador del límite.

        **** Construcción del grafo ****
        - Usar la mediana + seleccionar el nodo más cercano a la abundancia del nodo evaluado. - Pasamos al mínimo en lugar de mediana
        - ¿Que pasa si Node/Neigh pertenecen al propio union_set? Pues obviamente si se construye algún camino sin ellos estos no pueden pertenecer a la misma hebra.
        - Matiz adicional: si un unitig pertenece a union_set entonces hay que tener cuidado por que va a ser probablemente un origen + no se puede contar su longitud íntegra
        - Por que no directamente los nodos Node/Neigh como parte de la información de emparejados?
        - Añadidos además los nodos intermedios de entrada como fake nodes -> estos no se tendrán en cuenta en la incorporación de los caminos pero si como posibles constructores
        de los mismos. La idea es quedarnos con los legítimos esquivando los falsos. (__reach incorpora in_nodes y se maneja con true_nodes); pero ojo solo se añade 1 y cuando
        se realiza un split del camino (se encuentra un nodo branched entonces se resetea). ¿Para que agregar 40 diferentes si realmente a nosotros nos interesa la legitimidad en
        una línea recta?

        **** Paired-end ****
        - New trial - vamos a asociar los pe_information con cada par de nodos:
            + Usamos un bitmap para marcar las lecturas que efectivamente guardan información de transición de unitigs.
            + Asociamos la información según corresponda:
                ++ u1 - [u2,u3] = getNeighbors(u1); paired-end(u1,u2) paired-end(u1,u3)
                ++ Recordar rc